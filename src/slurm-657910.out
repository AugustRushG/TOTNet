W1206 18:16:58.984845 140182918645568 torch/distributed/run.py:779] 
W1206 18:16:58.984845 140182918645568 torch/distributed/run.py:779] *****************************************
W1206 18:16:58.984845 140182918645568 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1206 18:16:58.984845 140182918645568 torch/distributed/run.py:779] *****************************************
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, dout):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, dout):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, dout, *args):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, dout, *args):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float("inf")), return_final_states=False, activation="silu",
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, dout, *args):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float("inf")), return_final_states=False, activation="silu",
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, dout, *args):
Number of GPUs: 2
GPU 0: NVIDIA L40S
GPU 1: NVIDIA L40S
Running on rank 1, using GPU 1
Use GPU: 1 for training
Running on rank 0, using GPU 0
Use GPU: 0 for training
Building Motion Light model...../logs/normal_tracking_288_512_motion_light_tennis_weighted(5)
 normal_tracking_288_512_motion_light_tennis_weighted(5)
2024-12-06 18:17:34,565: logger.py - info(), at Line 39:INFO:
>>> Created a new logger
2024-12-06 18:17:34,566: logger.py - info(), at Line 39:INFO:
>>> configs: {'seed': 2024, 'working_dir': '../', 'saved_fn': 'normal_tracking_288_512_motion_light_tennis_weighted(5)', 'no_val': False, 'no_test': True, 'val_size': 0.2, 'num_samples': None, 'batch_size': 16, 'num_workers': 8, 'distributed': True, 'print_freq': 100, 'checkpoint_freq': 2, 'earlystop_patience': None, 'save_test_output': False, 'pretrained_path': None, 'backbone_choice': 'single', 'backbone_pretrained': True, 'backbone_out_channels': 2048, 'transfromer_dmodel': 512, 'transformer_nhead': 8, 'num_feature_levels': 1, 'num_classes': 1, 'num_queries': 20, 'model_choice': 'motion_light', 'video_path': None, 'output_format': 'text', 'show_image': False, 'save_demo_output': False, 'num_frames': 5, 'interval': 1, 'start_epoch': 1, 'num_epochs': 20, 'lr': 0.0005, 'minimum_lr': 1e-07, 'momentum': 0.9, 'weight_decay': 5e-05, 'optimizer_type': 'adamw', 'lr_type': 'plateau', 'lr_factor': 0.5, 'lr_step_size': 5, 'lr_patience': 3, 'occluded_prob': 0.0, 'ball_size': 4, 'dataset_choice': 'tennis', 'event': False, 'bidirect': False, 'smooth_labelling': False, 'img_size': [288, 512], 'world_size': 2, 'rank': 0, 'dist_url': 'env://', 'dist_backend': 'nccl', 'gpu_idx': 0, 'no_cuda': False, 'multiprocessing_distributed': True, 'device': device(type='cuda', index=0), 'ngpus_per_node': 2, 'pin_memory': True, 'org_size': (1080, 1920), 'fps': 25, 'results_dir': '../results', 'logs_dir': '../logs/normal_tracking_288_512_motion_light_tennis_weighted(5)', 'checkpoints_dir': '../checkpoints/normal_tracking_288_512_motion_light_tennis_weighted(5)', 'frame_dir': '/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/demo', 'dataset_dir': '/home/s224705071/github/TT/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch/dataset', 'train_game_list': ['game_1', 'game_2', 'game_3', 'game_4', 'game_5'], 'test_game_list': ['test_1', 'test_2', 'test_3', 'test_4', 'test_5', 'test_6', 'test_7'], 'events_dict': {'bounce': 0, 'net': 1, 'empty_event': 2}, 'events_weights_loss_dict': {'bounce': 1.0, 'net': 3.0}, 'tennis_dataset_dir': '/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tennis_data', 'tennis_train_game_list': ['game1', 'game2', 'game3', 'game4', 'game5', 'game6', 'game7', 'game8'], 'tennis_test_game_list': ['game9', 'game10'], 'badminton_dataset_dir': '/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/badminton/TrackNetV2', 'badminton_train_game_list': ['Amateur', 'Professional'], 'badminton_test_game_list': ['Test'], 'is_master_node': True}
Building Motion Light model...
2024-12-06 18:17:35,910: logger.py - info(), at Line 39:INFO:
number of trained parameters of the model: 8654467
2024-12-06 18:17:35,910: logger.py - info(), at Line 39:INFO:
>>> Loading dataset & getting dataloader...
0 skipped frame due to due to invalid last label
0 skipped frame due to due to invalid last label
GPU 1 (Rank 1): 12894 samples total, 6447 samples for this GPU
  0%|          | 0/806 [00:00<?, ?it/s][ WARN:0@38.463] global loadsave.cpp:241 findDecoder imread_('/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tennis_data/game1/Clip13/-002.jpg'): can't open/read file: check file path/integrity
[ WARN:0@38.469] global loadsave.cpp:241 findDecoder imread_('/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tennis_data/game1/Clip13/-001.jpg'): can't open/read file: check file path/integrity
2024-12-06 18:17:41,960: logger.py - info(), at Line 39:INFO:
Batch data shape: torch.Size([8, 5, 3, 288, 512])
GPU 0 (Rank 0): 12894 samples total, 6447 samples for this GPU
2024-12-06 18:17:41,960: logger.py - info(), at Line 39:INFO:
number of batches in train set: 806
2024-12-06 18:17:41,961: logger.py - info(), at Line 39:INFO:
number of batches in val set: 202
2024-12-06 18:17:41,961: logger.py - info(), at Line 39:INFO:
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
2024-12-06 18:17:41,961: logger.py - info(), at Line 39:INFO:
=================================== 1/20 ===================================
2024-12-06 18:17:41,961: logger.py - info(), at Line 39:INFO:
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
2024-12-06 18:17:41,961: logger.py - info(), at Line 39:INFO:
>>> Epoch: [1/20] learning rate: 5.00e-04
  0%|          | 0/806 [00:00<?, ?it/s][ WARN:0@40.348] global loadsave.cpp:241 findDecoder imread_('/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tennis_data/game3/Clip7/-004.jpg'): can't open/read file: check file path/integrity
[ WARN:0@40.353] global loadsave.cpp:241 findDecoder imread_('/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tennis_data/game3/Clip7/-003.jpg'): can't open/read file: check file path/integrity
[ WARN:0@40.358] global loadsave.cpp:241 findDecoder imread_('/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tennis_data/game3/Clip7/-002.jpg'): can't open/read file: check file path/integrity
[ WARN:0@40.363] global loadsave.cpp:241 findDecoder imread_('/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tennis_data/game3/Clip7/-001.jpg'): can't open/read file: check file path/integrity
[ WARN:0@41.756] global loadsave.cpp:241 findDecoder imread_('/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tennis_data/game5/Clip14/-004.jpg'): can't open/read file: check file path/integrity
[ WARN:0@41.763] global loadsave.cpp:241 findDecoder imread_('/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tennis_data/game5/Clip14/-003.jpg'): can't open/read file: check file path/integrity
[ WARN:0@41.770] global loadsave.cpp:241 findDecoder imread_('/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tennis_data/game5/Clip14/-002.jpg'): can't open/read file: check file path/integrity
[ WARN:0@41.778] global loadsave.cpp:241 findDecoder imread_('/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tennis_data/game5/Clip14/-001.jpg'): can't open/read file: check file path/integrity
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/conv.py:454: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1031.)
  return F.conv2d(input, weight, bias, self.stride,
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/conv.py:454: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1031.)
  return F.conv2d(input, weight, bias, self.stride,
  0%|          | 1/806 [00:12<2:50:34, 12.71s/it]  0%|          | 1/806 [00:08<1:50:33,  8.24s/it]