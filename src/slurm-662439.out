Wed Jan 22 14:25:38 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-PCIE-40GB          Off | 00000000:81:00.0 Off |                    0 |
| N/A   34C    P0              40W / 250W |      0MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA A100-PCIE-40GB          Off | 00000000:C1:00.0 Off |                    0 |
| N/A   33C    P0              37W / 250W |      0MiB / 40960MiB |      4%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
W0122 14:25:51.150685 140680195422016 torch/distributed/run.py:779] 
W0122 14:25:51.150685 140680195422016 torch/distributed/run.py:779] *****************************************
W0122 14:25:51.150685 140680195422016 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0122 14:25:51.150685 140680195422016 torch/distributed/run.py:779] *****************************************
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, dout):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, dout):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, dout, *args):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, dout, *args):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float("inf")), return_final_states=False, activation="silu",
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, dout, *args):
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float("inf")), return_final_states=False, activation="silu",
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, dout, *args):
Number of GPUs: 2
GPU 0: NVIDIA A100-PCIE-40GB
GPU 1: NVIDIA A100-PCIE-40GB
Running on rank 0, using GPU 0
Use GPU: 0 for training
Running on rank 1, using GPU 1
Use GPU: 1 for training
../logs/tracking_288_512_motion_light_TTA(3)_new_data tracking_288_512_motion_light_TTA(3)_new_data
Building Motion Light model...
2025-01-22 14:26:39,909: logger.py - info(), at Line 39:INFO:
>>> Created a new logger
2025-01-22 14:26:39,909: logger.py - info(), at Line 39:INFO:
>>> configs: {'seed': 2024, 'working_dir': '../', 'saved_fn': 'tracking_288_512_motion_light_TTA(3)_new_data', 'no_val': False, 'no_test': True, 'test': False, 'val_size': 0.2, 'num_samples': None, 'batch_size': 24, 'num_workers': 8, 'distributed': True, 'print_freq': 100, 'checkpoint_freq': 1, 'earlystop_patience': None, 'save_test_output': False, 'pretrained_path': None, 'backbone_choice': 'single', 'backbone_pretrained': True, 'backbone_out_channels': 2048, 'transfromer_dmodel': 512, 'transformer_nhead': 8, 'num_feature_levels': 1, 'num_classes': 1, 'num_queries': 20, 'model_choice': 'motion_light', 'weighting_list': [1, 2, 2, 3], 'video_path': None, 'output_format': 'text', 'show_image': False, 'save_demo_output': False, 'num_frames': 3, 'interval': 1, 'start_epoch': 1, 'num_epochs': 30, 'lr': 0.0005, 'minimum_lr': 1e-07, 'momentum': 0.9, 'weight_decay': 5e-05, 'optimizer_type': 'adamw', 'loss_function': 'WBCE', 'lr_type': 'plateau', 'lr_factor': 0.5, 'lr_step_size': 5, 'lr_patience': 3, 'occluded_prob': 0.1, 'ball_size': 4, 'dataset_choice': 'tta', 'event': False, 'bidirect': False, 'sequential': False, 'smooth_labelling': False, 'img_size': [288, 512], 'world_size': 2, 'rank': 0, 'dist_url': 'env://', 'dist_backend': 'nccl', 'gpu_idx': 0, 'no_cuda': False, 'multiprocessing_distributed': True, 'device': device(type='cuda', index=0), 'ngpus_per_node': 2, 'pin_memory': True, 'org_size': (1080, 1920), 'fps': 25, 'results_dir': '../results', 'logs_dir': '../logs/tracking_288_512_motion_light_TTA(3)_new_data', 'checkpoints_dir': '../checkpoints/tracking_288_512_motion_light_TTA(3)_new_data', 'frame_dir': '/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/demo', 'dataset_dir': '/home/s224705071/github/TT/TTNet-Real-time-Analysis-System-for-Table-Tennis-Pytorch/dataset', 'train_game_list': ['game_1', 'game_2', 'game_3', 'game_4', 'game_5'], 'test_game_list': ['test_1', 'test_2', 'test_3', 'test_4', 'test_5', 'test_6', 'test_7'], 'events_dict': {'bounce': 0, 'net': 1, 'empty_event': 2}, 'events_weights_loss_dict': {'bounce': 1.0, 'net': 3.0}, 'tennis_dataset_dir': '/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tennis_data', 'tennis_train_game_list': ['game1', 'game2', 'game3', 'game4', 'game5', 'game6', 'game7', 'game8'], 'tennis_test_game_list': ['game9', 'game10'], 'badminton_dataset_dir': '/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/badminton/TrackNetV2', 'badminton_train_game_list': ['Amateur', 'Professional'], 'badminton_test_game_list': ['Test'], 'tta_dataset_dir': '/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/data/tta_dataset', 'tta_training_match_list': ['24Paralympics_FRA_F9_Lei_AUS_v_Xiong_CHN', '24Paralympics_FRA_M4_Addis_AUS_v_Chaiwut_THA'], 'tta_test_match_list': ['24Paralympics_FRA_M4_Addis_AUS_v_Chaiwut_THA'], 'is_master_node': True}
Building Motion Light model...
Rank 1: Model built with 8433155 parameters.
Rank 0: Model built with 8433155 parameters.
Model made parallel successfully.
using WBCE for loss function
Model made parallel successfully.
using WBCE for loss function
2025-01-22 14:26:41,618: logger.py - info(), at Line 39:INFO:
number of trained parameters of the model: 8433155
2025-01-22 14:26:41,618: logger.py - info(), at Line 39:INFO:
>>> Loading dataset & getting dataloader...
0 skipped frame due to due to invalid last label
GPU 1 (Rank 1): 5833 samples total, 2917 samples for this GPU
0 skipped frame due to due to invalid last label
  0%|          | 0/244 [00:00<?, ?it/s]2025-01-22 14:26:55,306: logger.py - info(), at Line 39:INFO:
Batch data shape: torch.Size([12, 3, 3, 288, 512])
GPU 0 (Rank 0): 5833 samples total, 2917 samples for this GPU
2025-01-22 14:26:55,306: logger.py - info(), at Line 39:INFO:
number of batches in train set: 244
2025-01-22 14:26:55,306: logger.py - info(), at Line 39:INFO:
number of batches in val set: 61
2025-01-22 14:26:55,306: logger.py - info(), at Line 39:INFO:
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
2025-01-22 14:26:55,307: logger.py - info(), at Line 39:INFO:
=================================== 1/30 ===================================
2025-01-22 14:26:55,307: logger.py - info(), at Line 39:INFO:
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
2025-01-22 14:26:55,307: logger.py - info(), at Line 39:INFO:
>>> Epoch: [1/30] learning rate: 5.00e-04
  0%|          | 0/244 [00:00<?, ?it/s]/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/conv.py:454: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1031.)
  return F.conv2d(input, weight, bias, self.stride,
/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/conv.py:454: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1031.)
  return F.conv2d(input, weight, bias, self.stride,
  0%|          | 1/244 [00:17<1:10:49, 17.49s/it]  0%|          | 1/244 [00:30<2:04:44, 30.80s/it]  0%|          | 1/244 [00:21<1:28:12, 21.78s/it]
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/src/main.py", line 485, in <module>
[rank0]:     main()
[rank0]:   File "/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/src/main.py", line 66, in main
[rank0]:     main_worker(configs)
[rank0]:   File "/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/src/main.py", line 217, in main_worker
[rank0]:     train_loss = train_one_epoch(train_loader, model, optimizer, loss_func, scaler, epoch, configs, logger)
[rank0]:   File "/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/src/main.py", line 307, in train_one_epoch
[rank0]:     output_heatmap, cls_score = model(batch_data) # output in shape ([B, W],[B, H]) if output heatmap
[rank0]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/src/model/motion_model_light.py", line 333, in forward
[rank0]:     x = self.block7(x, spatial_out1, temporal_out1) #outputs [B*N, C, H, W] 
[rank0]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/src/model/motion_model_light.py", line 134, in forward
[rank0]:     x = torch.concat((x, spatial_concat), dim=1)
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacity of 39.39 GiB of which 1.15 GiB is free. Including non-PyTorch memory, this process has 38.23 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|          | 1/244 [00:35<2:25:41, 35.97s/it]
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/src/main.py", line 485, in <module>
[rank1]:     main()
[rank1]:   File "/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/src/main.py", line 66, in main
[rank1]:     main_worker(configs)
[rank1]:   File "/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/src/main.py", line 217, in main_worker
[rank1]:     train_loss = train_one_epoch(train_loader, model, optimizer, loss_func, scaler, epoch, configs, logger)
[rank1]:   File "/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/src/main.py", line 307, in train_one_epoch
[rank1]:     output_heatmap, cls_score = model(batch_data) # output in shape ([B, W],[B, H]) if output heatmap
[rank1]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank1]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank1]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/src/model/motion_model_light.py", line 333, in forward
[rank1]:     x = self.block7(x, spatial_out1, temporal_out1) #outputs [B*N, C, H, W] 
[rank1]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/s224705071/github/PhysicsInformedDeformableAttentionNetwork/src/model/motion_model_light.py", line 134, in forward
[rank1]:     x = torch.concat((x, spatial_concat), dim=1)
[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.80 GiB. GPU 1 has a total capacity of 39.39 GiB of which 1.15 GiB is free. Including non-PyTorch memory, this process has 38.23 GiB memory in use. Of the allocated memory 28.85 GiB is allocated by PyTorch, and 8.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
W0122 14:27:18.998420 140680195422016 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 4161943 closing signal SIGTERM
E0122 14:27:22.870545 140680195422016 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 4161942) of binary: /home/s224705071/.conda/envs/PIDA/bin/python
Traceback (most recent call last):
  File "/home/s224705071/.conda/envs/PIDA/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/s224705071/.conda/envs/PIDA/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-22_14:27:18
  host      : boromir
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4161942)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
